% !TEX root = main.tex
\section{Related Work}
\label{sect:related_work}
To the best of our knowledge, this is the first replication work that takes the identical approach to replicate the work in~\cite{Brunet2014a}. However, this study has been revisited once before by~\cite{Shakiba2016} to determine if it is possible to predict a single commit message is about design or not. The authors of \cite{Shakiba2016} manually annotated their own dataset that they used as train data and implemented a variety of classifiers to determine the best performing classifier. As they did not used the same dataset and procedures as~\cite{Brunet2014a}, they did not get the accuracy which was 87.58\% for their best performing classifier, Random Forest.

If we do not limit ourselves to strict replication, we can find some literature which implements similar work. Maldonado in~\cite{Maldonado2017} tried to identify self admitted technical debt which can be perceived as one kind of design issue using Natural Language Processing. Like~\cite{Brunet2014a}, they manually classified a set of data which is used as training data for the Stanford Classifier, which is a Java implementation of a maximum entropy classifier. Using this classifier they achieved 90\% accuracy on test data and found out that, 23\% of the comments in both design and requirement comments are technical debt. A recent manual investigation on Github discussion by Viviani~\cite{Viviani2018} shows some detailed information about the design discussions. He conducted an empirical study on the discussions and matched their result with~\cite{Brunet2014a} to validate their claim of 23-24\% design discussions being present in the discussions.   
